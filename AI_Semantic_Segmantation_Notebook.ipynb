{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWvxgAUmot3pigHNH4er0X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatelVatsalB21/AI-Road-Semantic-Segmentation/blob/test/AI_Semantic_Segmantation_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBLo2CVs7LJZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from tqdm import notebook\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40SiAgQm7Mlc"
      },
      "source": [
        "def plotter(img,mask):\n",
        "    fig,axes=plt.subplots(1,2)\n",
        "    axes[0].imshow(img)\n",
        "    plt.imshow(mask)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TADecSR67QDM"
      },
      "source": [
        "input_images = []\n",
        "mask_images = []\n",
        "\n",
        "image_path = \"../content/CameraRGB/\"\n",
        "mask_path = \"../content/CameraSeg/\"\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "image_list = [image_path + i for i in image_list]\n",
        "mask_list = [mask_path + i for i in mask_list]\n",
        "\n",
        "for i in notebook.tqdm(range(len(image_list))):\n",
        "    img, mask = cv2.imread(image_list[i]), cv2.imread(mask_list[i])[:, :, 2]\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    mask = cv2.resize(mask, (256, 256,))\n",
        "    input_images.append(img)\n",
        "    mask_images.append(mask)\n",
        "\n",
        "input_images = np.array(input_images)\n",
        "input_images = input_images / 255.\n",
        "mask_images = np.array(mask_images)\n",
        "mask_images = mask_images.reshape((mask_images.shape[0], mask_images.shape[1], mask_images.shape[2], 1))\n",
        "input_img = input_images[0]\n",
        "# h = input_img.shape[0]\n",
        "# w = input_img.shape[1]\n",
        "# l = input_img.shape[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhBXMnH_7SGt"
      },
      "source": [
        "print(\"started pipeline\")\n",
        "input_images = []\n",
        "mask_images = []\n",
        "\n",
        "def process_data():\n",
        "    print(\"process_data\")\n",
        "    image_path = \"../content/CameraRGB/\"\n",
        "    mask_path = \"../content/CameraSeg/\"\n",
        "    image_list = os.listdir(image_path)\n",
        "    mask_list = os.listdir(mask_path)\n",
        "    image_list = [image_path + i for i in image_list]\n",
        "    mask_list = [mask_path + i for i in mask_list]\n",
        "\n",
        "\n",
        "    for i in notebook.tqdm(range(1000)):\n",
        "        img,mask= cv2.imread(image_list[i]),cv2.imread(mask_list[i])[:,:,2]\n",
        "        img=cv2.resize(img,(256,256))\n",
        "        mask=cv2.resize(mask,(256,256,))\n",
        "        input_images.append(img)\n",
        "        mask_images.append(mask)\n",
        "\n",
        "process_data()\n",
        "\n",
        "input_images = np.array(input_images)\n",
        "input_images = input_images/255.\n",
        "mask_images = np.array(mask_images)\n",
        "mask_images = mask_images.reshape((mask_images.shape[0], mask_images.shape[1], mask_images.shape[2], 1))\n",
        "\n",
        "print(mask_images[0])\n",
        "plt.imshow(mask_images[0])\n",
        "plt.show()\n",
        "\n",
        "print(input_images.shape, mask_images.shape)\n",
        "\n",
        "\n",
        "input_img = input_images[0]\n",
        "output_img = mask_images[0]\n",
        "\n",
        "img_ht = input_img.shape[0]\n",
        "img_wd = input_img.shape[1]\n",
        "img_ly = input_img.shape[2]\n",
        "\n",
        "print(img_ht, img_wd, img_ly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dckIcR_-7j98"
      },
      "source": [
        "    inputs = Input(shape=(img_ht,img_wd,img_ly), name = 'img_input')\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "     \n",
        "        residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = keras.layers.add([x, residual]) \n",
        "        previous_block_activation = x \n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = UpSampling2D(2)(x)\n",
        "\n",
        "        residual = UpSampling2D(2)(previous_block_activation)\n",
        "        residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = keras.layers.add([x, residual])  \n",
        "        previous_block_activation = x \n",
        "\n",
        "    outputs = Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    model = Model(inputs = [inputs], outputs = [outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F22jEZV7nUM"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model = get_model((256,256), 13)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "callbacks = [\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-12),\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjCgcnpo7u97"
      },
      "source": [
        "history = model.fit(input_images, mask_images, batch_size=32, epochs = 10, callbacks = callbacks, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L8UW2Rm7wqs"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QmnOVUT7xIk"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label = 'Training')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Validation')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label = 'Training')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation')\n",
        "plt.title('loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-841HYAV7yo7"
      },
      "source": [
        "model.save(\"/content/semantic_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrH4t1ls70vM"
      },
      "source": [
        "test = input_images[0]\n",
        "getshape=test.shape\n",
        "pred = model.predict(test.reshape(1,getshape[0],getshape[1],getshape[2]))\n",
        "\n",
        "print(pred.shape)        \n",
        "newimg = np.zeros((256,256))\n",
        "print(pred)\n",
        "for i in range(13):\n",
        "    for j in range(256):\n",
        "        for k in range(256):\n",
        "            if pred[0,j,k,i] > 0.5:\n",
        "                newimg[j,k] = i\n",
        "\n",
        "plotter(test,newimg)\n",
        "# plt.imshow(newimg, cmap=\"Paired\")\n",
        "plotter(test,input_images[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}